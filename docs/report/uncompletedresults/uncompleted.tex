%!TEX program = xelatex
%!TEX spellcheck = en_GB
\documentclass[final]{report}
\input{../../.library/preamble.tex}
\input{../../.library/style.tex}
\addbibresource{../../.library/bibliography.bib}

\begin{document}
\chapter{Uncompleted Results}
\label{ch:Uncompleted Results}

This chapter contains work that is uncompleted that was intended to be part of the project, but for several possible reasons was not included. That could be not enough time, unsuited tools or we couldn't get it to work. 

\section{SpeechRecognition}
Originally we wanted to analyse the interaction between the streamer and the users, so we needed data from the streamer.
The downloaded audio was used with the python library SpeechRecognition. %https://pypi.python.org/pypi/SpeechRecognition/%.
Different speech recognition toolkits were looked into:
\begin{enumerate}
\item Python speech recognition 3.7.1 which includes CMU Sphinx as speech recognition software. It is very slow as the processing must happen in real-time.
\item Dragon Speech Recognition Software, which is a professional software package. However it has high price which makes it not viable for our project.
\item Google Cloud Speech API, google has a free tool that can be used for speech recognition. It is however very slow like all other tools and does not return usable text.
\end{enumerate}

All the tools used work in real-time, so this means they are all very slow (each second of audio takes 1 second to process). Likewise none of them returned usable data that doesn't contain a significant amount of errors.
This is expected as speech recognition is still not at the required level to properly gather reliable data, moreover music is usually played on stream and together with game sounds this interferes significantly with the speech recognition.
We conclude that speech recognition on a massive dataset is still not a viable option.
In the near future when services are cheaper and the recognition technology is more advanced it could become interesting to look into this.

\section{Training}
To analyse the chat data, we had to gather a training set in which the chat is rated based on their toxicity.
We converted the compressed pickle file to a chat log from the MLG channel to an SQL insert statement to store the chat into a MySQL database.
A website implemented in JavaScript and PHP showed this chat and we manually rated each chat message with a 1 to 5 (1 being non-toxic, 5 being very toxic). The final training set is also filtered on words that are shorter than 3 letters to remove even more noise. Below the web page where the data can be trained is shown in \ref{fig:rating}.

\begin{figure}[h]
\includegraphics[scale=0.5]{rating}
\caption{Web page to train our dataset}
\label{fig:rating}
\end{figure}

On the far left the message number and the timestamp of the message is shown, together with how often the message has been rated before (between the brackets). In the middle the user (bold) and the message sent by the user can be seen to determine the rating. On the far right are the rating options, with 1 being non toxic and 5 very toxic.

\section{Classifier}
%NLTK

%From results, about the classifier
After the training set is complete and present in the database it can be used to classify other data. The classifier downloads a sub set of the manually classified data, then extracts word based features and trains a Naive Bayes or MaxEnt classifier.
The problem was in the initial distribution of all the classes for the classifier.
There are way too many messages rated 1 (non-toxic).
Thus the output of the classified was mostly 1.000 (float).

The idea was that the results would give an average degree of toxicity for certain streamers to compare, but also users individually per channel viewed. Based on those results different viewers could also be compared in different channels to see how the toxicity in a channel affects the viewers. So in other words if the toxicity in twitch streams is also contagious.


\end{document}